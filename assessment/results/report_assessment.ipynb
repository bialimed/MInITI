{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd07a393-b98c-4c22-be22-f587405796e4",
   "metadata": {},
   "source": [
    "# MInITI assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "other-there",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import statistics\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "missing-tongue",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess\n",
    "\n",
    "def getLoci(dataset_df):\n",
    "    loci = []\n",
    "    for col_name in dataset_df.columns:\n",
    "        if col_name != \"train_nb_spl_stable\":\n",
    "            match = re.match(\"^train_nb_(.+)_stable$\", col_name)\n",
    "            if match is not None:\n",
    "                loci.append(match.group(1))\n",
    "    return sorted(loci)\n",
    "\n",
    "\n",
    "def getPredStatusEval(row, locus):\n",
    "    status = \"Undetermined\"\n",
    "    if row[\"{}_observed_status\".format(locus)] != \"Undetermined\" and row[\"{}_expected_status\".format(locus)] != \"Undetermined\":\n",
    "        if row[\"{}_expected_status\".format(locus)] == row[\"{}_observed_status\".format(locus)]:\n",
    "            status = \"right\"\n",
    "        else:\n",
    "            status = \"wrong\"\n",
    "    return status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trying-medline",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuray\n",
    "\n",
    "def getAccuracyDf(loci, results_df):\n",
    "    accuracy_rows = []\n",
    "    datasets_ids = list(set(results_df[\"dataset_id\"]))\n",
    "    configurations = sorted(list(set(results_df[\"config\"])))\n",
    "    for dataset_id in datasets_ids:\n",
    "        for config in configurations:\n",
    "            cfg_params = {}\n",
    "            # Select sub-dataframe for dataset and configuration\n",
    "            dataset = results_df[\n",
    "                (results_df[\"dataset_id\"] == dataset_id) &\n",
    "                (results_df[\"config\"] == config)\n",
    "            ]\n",
    "            # Get right, wrong and Undetermined counts\n",
    "            ct_status_by_locus = {\n",
    "                locus: {\"right\": 0, \"wrong\": 0, \"Undetermined\": 0} for locus in loci\n",
    "            }\n",
    "            for idx, row in dataset.iterrows():\n",
    "                for locus in loci:\n",
    "                    if row[\"{}_expected_status\".format(locus)] != \"Undetermined\":\n",
    "                        status = getPredStatusEval(row, locus)\n",
    "                        ct_status_by_locus[locus][status] += 1\n",
    "                cfg_params = {\n",
    "                    \"classifier\": row[\"classifier\"],\n",
    "                    \"min_support\": row[\"min_support\"],\n",
    "                    \"padding\": row[\"padding\"],\n",
    "                    \"stitching\": row[\"stitching\"],\n",
    "                    \"duplicates\": row[\"duplicates\"]\n",
    "                }\n",
    "            # Resume by locus\n",
    "            for locus in loci:\n",
    "                nb_determined = ct_status_by_locus[locus][\"right\"] + ct_status_by_locus[locus][\"wrong\"]\n",
    "                accuracy_rows.append([\n",
    "                    dataset_id,\n",
    "                    locus,\n",
    "                    config,\n",
    "                    cfg_params[\"classifier\"],\n",
    "                    cfg_params[\"min_support\"],\n",
    "                    cfg_params[\"padding\"],\n",
    "                    cfg_params[\"stitching\"],\n",
    "                    cfg_params[\"duplicates\"],\n",
    "                    (None if nb_determined == 0 else ct_status_by_locus[locus][\"right\"] / nb_determined),\n",
    "                    ct_status_by_locus[locus][\"right\"],\n",
    "                    ct_status_by_locus[locus][\"wrong\"],\n",
    "                    ct_status_by_locus[locus][\"Undetermined\"]\n",
    "                ])\n",
    "    accuracy_df = pd.DataFrame.from_records(\n",
    "        accuracy_rows,\n",
    "        columns=[\n",
    "            \"dataset_id\", \"locus\",\n",
    "            \"config\", \"classifier\", \"min_support\", \"padding\", \"stitching\", \"duplicates\",\n",
    "            \"accuracy\", \"nb_right_prediction\", \"nb_wrong_prediction\", \"nb_without_prediction\"\n",
    "        ]\n",
    "    )\n",
    "    return accuracy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stunning-howard",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consensus method\n",
    "\n",
    "def getMajority(status):\n",
    "    consensus = \"Undetermined\"\n",
    "    nb_by_status = {\"MSI\": 0, \"MSS\": 0, \"Undetermined\": 0}\n",
    "    for curr_status in status:\n",
    "        nb_by_status[curr_status] += 1\n",
    "    if nb_by_status[\"MSI\"] > nb_by_status[\"MSS\"]:\n",
    "        consensus = \"MSI\"\n",
    "    elif nb_by_status[\"MSI\"] < nb_by_status[\"MSS\"]:\n",
    "        consensus = \"MSS\"\n",
    "    return consensus\n",
    "\n",
    "\n",
    "def getAgreement(status):\n",
    "    agreement = \"Undetermined\"\n",
    "    list_of_pred = [curr_status for curr_status in status]\n",
    "    if len(set(list_of_pred)) == 1:\n",
    "        agreement = list_of_pred[0]\n",
    "    return agreement\n",
    "\n",
    "\n",
    "def getMethodsConsensusDf(res_df, loci, used_clf=None, consensus_method=\"majority\"):\n",
    "    if used_clf is None:\n",
    "        used_clf = sorted(list(set(res_df[\"classifier\"])))\n",
    "    nb_used_clf = len(used_clf)\n",
    "    consensus_data = {}\n",
    "    consensus_rows = []\n",
    "    for idx_row, curr_row in res_df.iterrows():\n",
    "        res_id = \"{}_{}_{}\".format(curr_row[\"dataset_id\"], curr_row[\"lib_name\"], curr_row[\"config\"].split(\",\", 1)[1])\n",
    "        if curr_row[\"classifier\"] in used_clf:\n",
    "            if res_id not in consensus_data:\n",
    "                consensus_data[res_id] = {\n",
    "                    \"dataset_id\": curr_row[\"dataset_id\"],\n",
    "                    \"lib_name\": curr_row[\"lib_name\"],\n",
    "                    \"spl_name\": curr_row[\"spl_name\"]\n",
    "                }\n",
    "                for elt in [\"spl\"] + loci:\n",
    "                    consensus_data[res_id][elt + \"_expected_status\"] = curr_row[elt + \"_expected_status\"]\n",
    "                    consensus_data[res_id][elt + \"_observed_status\"] = [curr_row[elt + \"_observed_status\"]]\n",
    "            else:\n",
    "                for elt in [\"spl\"] + loci:\n",
    "                    consensus_data[res_id][elt + \"_observed_status\"].append(curr_row[elt + \"_observed_status\"])\n",
    "            if len(consensus_data[res_id][\"spl_observed_status\"]) == nb_used_clf:\n",
    "                cons_row = {k: v for k, v in consensus_data[res_id].items()}\n",
    "                cons_row[\"classifier\"] = consensus_method\n",
    "                cons_row[\"padding\"] = curr_row[\"padding\"]\n",
    "                cons_row[\"min_support\"] = curr_row[\"min_support\"]\n",
    "                cons_row[\"stitching\"] = curr_row[\"stitching\"]\n",
    "                cons_row[\"duplicates\"] = curr_row[\"duplicates\"]\n",
    "                cons_row[\"config\"] = \"clf={},{}\".format(consensus_method, curr_row[\"config\"].split(\",\", 1)[1])\n",
    "                for elt in [\"spl\"] + loci:\n",
    "                    if consensus_method == \"majority\":\n",
    "                        cons_row[elt + \"_observed_status\"] = getMajority(cons_row[elt + \"_observed_status\"])\n",
    "                    else:\n",
    "                        cons_row[elt + \"_observed_status\"] = getAgreement(cons_row[elt + \"_observed_status\"])\n",
    "                    cons_row[elt + \"_pred_score\"] = None\n",
    "                    cons_row[elt + \"_pred_is_ok\"] = None\n",
    "                    if elt != \"spl\":\n",
    "                        cons_row[elt + \"_pred_support\"] = None\n",
    "                for elt in [\"spl\"] + loci:\n",
    "                    cons_row[elt + \"_pred_is_ok\"] = getPredStatusEval(cons_row, elt)\n",
    "                consensus_rows.append(cons_row)\n",
    "                del(consensus_data[res_id])\n",
    "    return pd.DataFrame(consensus_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "friendly-efficiency",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction score\n",
    "\n",
    "def getLociDf(loci, results_df):\n",
    "    loci_rows = []\n",
    "    for idx, row in results_df.iterrows():\n",
    "        for locus in loci:\n",
    "            if row[\"{}_expected_status\".format(locus)] != \"Undetermined\":\n",
    "                loci_rows.append([\n",
    "                    row[\"dataset_id\"],\n",
    "                    locus,\n",
    "                    row[\"config\"],\n",
    "                    row[\"classifier\"],\n",
    "                    row[\"{}_pred_score\".format(locus)],\n",
    "                    getPredStatusEval(row, locus) + \"_classif\"\n",
    "                ])\n",
    "    loci_df = pd.DataFrame.from_records(loci_rows, columns=[\"dataset_id\", \"locus\", \"config\", \"classifier\", \"prediction_score\", \"prediction_status\"])\n",
    "    return loci_df\n",
    "\n",
    "\n",
    "def writeScorePredStatus(loci, results_df, nb_col=1, subplots_adjust=0.9):\n",
    "    loci_df = getLociDf(loci, results_df)\n",
    "    loci_df = loci_df[loci_df[\"prediction_status\"] != \"Undetermined_classif\"]\n",
    "    loci_df = loci_df[loci_df[\"classifier\"] != retained[\"consensus\"][\"method\"]]\n",
    "    prediction_status_order = [\"right_classif\", \"wrong_classif\"]\n",
    "    graph = sns.catplot(\n",
    "        x=\"classifier\",\n",
    "        y=\"prediction_score\",\n",
    "        hue=\"prediction_status\",\n",
    "        col=\"locus\",\n",
    "        col_wrap=nb_col,\n",
    "        data=loci_df,\n",
    "        kind=\"box\",\n",
    "        medianprops=dict(linewidth=2, color='firebrick'),\n",
    "        order=sorted(list(set(loci_df[\"classifier\"]))),\n",
    "        hue_order=prediction_status_order\n",
    "    )\n",
    "    for ax in graph.axes.flat:\n",
    "        ax.set(xlabel='Classifiers', ylabel='Prediction score')\n",
    "        ax.tick_params(axis='x', rotation=90)\n",
    "    plt.subplots_adjust(top=subplots_adjust, hspace=0.2)\n",
    "    plt.gcf().suptitle(\"Confidence scores evaluation\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aging-hudson",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction status\n",
    "\n",
    "def writePredStatus(accuracy_df, nb_col=1, subplots_adjust=0.9):\n",
    "    loci = sorted(set(accuracy_df[\"locus\"]))\n",
    "    # Agglomerate dataset info\n",
    "    status_rows = []\n",
    "    for idx, row in accuracy_df.iterrows():\n",
    "        nb_evaluated = row[\"nb_right_prediction\"] + row[\"nb_wrong_prediction\"] + row[\"nb_without_prediction\"]\n",
    "        if nb_evaluated == 0:\n",
    "            continue\n",
    "        for status in [\"nb_right_prediction\", \"nb_wrong_prediction\", \"nb_without_prediction\"]:\n",
    "            prediction_status = prediction_status = status.split(\"_\")[1] + \"_classif\"\n",
    "            status_rows.append([\n",
    "                row[\"dataset_id\"],\n",
    "                row[\"locus\"],\n",
    "                row[\"config\"],\n",
    "                prediction_status,\n",
    "                row[status] * 100 / nb_evaluated\n",
    "            ])\n",
    "    status_df = pd.DataFrame.from_records(status_rows, columns=[\"dataset_id\", \"locus\", \"config\", \"prediction_status\", \"% of samples\"])\n",
    "    # Plot status\n",
    "    prediction_status_order = [\"wrong_classif\", \"without_classif\"]\n",
    "    status_df = status_df[status_df[\"prediction_status\"] != \"right_classif\"]\n",
    "    g = sns.catplot(\n",
    "        y=\"% of samples\",\n",
    "        x=\"prediction_status\",\n",
    "        hue=\"config\",\n",
    "        col=\"locus\",\n",
    "        col_wrap=nb_col,\n",
    "        data=status_df,\n",
    "        kind=\"box\",\n",
    "        order=prediction_status_order,\n",
    "        medianprops=dict(linewidth=2, color='firebrick')\n",
    "    )\n",
    "    plt.subplots_adjust(top=subplots_adjust, hspace=0.2)\n",
    "    plt.gcf().suptitle(\"Classification accuracy\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aerial-wheel",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attempted-might",
   "metadata": {},
   "outputs": [],
   "source": [
    "retained = {\n",
    "    \"classifiers\": {\"MSIsensor-pro_pro\", \"mSINGSUp\", \"agreement\", \"LogisticRegression\"},\n",
    "    \"consensus\": {\n",
    "        \"components\": [\"MSIsensor-pro_pro\", \"LogisticRegression\"],\n",
    "        \"method\": \"agreement\"\n",
    "    },\n",
    "    \"duplicates\": \"with\",\n",
    "    \"min_support\": 150,\n",
    "    \"padding\": 2,\n",
    "    \"stitching\": \"without\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entitled-blair",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init data\n",
    "dataset_df = pd.read_csv(\"mmr_v1_datasets.tsv\", sep='\\t')\n",
    "results_df = pd.read_csv(\"mmr_v1_results.tsv\", sep='\\t')\n",
    "#dataset_df = pd.read_csv(\"solid_tumor_v5.1_datasets.tsv\", sep='\\t')\n",
    "#results_df = pd.read_csv(\"solid_tumor_v5.1_results.tsv\", sep='\\t')\n",
    "loci = getLoci(dataset_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bridal-favorite",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data and agreement\n",
    "results_df[\"spl_name\"] = results_df[\"lib_name\"].apply(lambda lib_name: lib_name.split(\"_\")[0])\n",
    "for locus in loci:\n",
    "    results_df[\"{}_pred_is_ok\".format(locus)] = results_df.apply(lambda row: getPredStatusEval(row, locus), axis=1)\n",
    "results_df[\"spl_pred_is_ok\"] = results_df.apply(lambda row: getPredStatusEval(row, \"spl\"), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surface-hamilton",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add agreement classifier\n",
    "consensus_df = getMethodsConsensusDf(results_df, loci, retained[\"consensus\"][\"components\"], retained[\"consensus\"][\"method\"])\n",
    "results_df = pd.concat([results_df, consensus_df], sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitting-czech",
   "metadata": {},
   "source": [
    "## 2. Results from standard datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sapphire-airline",
   "metadata": {},
   "source": [
    "### 2.1. Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "particular-lender",
   "metadata": {},
   "outputs": [],
   "source": [
    "def datasetsComposition(dataset_df, mode=\"rate\"):\n",
    "    loci = set([title.replace(\"train_nb_\", \"\").replace(\"_unstable\", \"\") for title in dataset_df.columns if title.startswith(\"train_nb_\") and title.endswith(\"_unstable\")])\n",
    "    # Datasets descriptions\n",
    "    desc_rows = []\n",
    "    for idx, row in dataset_df.iterrows():\n",
    "        for dataset_type in [\"train\", \"test\"]:\n",
    "            for locus in loci:\n",
    "                nb_determined = row[\"{}_nb_{}_unstable\".format(dataset_type, locus)] + row[\"{}_nb_{}_stable\".format(dataset_type, locus)]\n",
    "                if nb_determined != 0:\n",
    "                    ratio_unstable = row[\"{}_nb_{}_unstable\".format(dataset_type, locus)] / nb_determined\n",
    "                    desc_rows.append([\n",
    "                        dataset_type,\n",
    "                        locus,\n",
    "                        ratio_unstable,\n",
    "                        row[\"{}_nb_{}_stable\".format(dataset_type, locus)],\n",
    "                        row[\"{}_nb_{}_unstable\".format(dataset_type, locus)]\n",
    "                    ])\n",
    "    desc_df = pd.DataFrame.from_records(desc_rows, columns=[\"dataset_type\", \"locus\", \"unstable_ratio\", \"nb_stable\", \"nb_unstable\"])\n",
    "    # Plot\n",
    "    if mode == \"rate\":\n",
    "        g = sns.boxplot(x=\"locus\", y=\"unstable_ratio\", hue=\"dataset_type\", data=desc_df, medianprops=dict(linewidth=2, color='firebrick'))\n",
    "        plt.subplots_adjust(top=0.95)\n",
    "        locs, labels = plt.xticks()\n",
    "        g.set_xticklabels(labels, rotation=90)\n",
    "        plt.gcf().suptitle(\"Rate of unstable ({} datasets)\".format(len(dataset_df)))\n",
    "    else:\n",
    "        g = sns.boxplot(x=\"locus\", y=\"nb_unstable\", hue=\"dataset_type\", data=desc_df, medianprops=dict(linewidth=2, color='firebrick'))\n",
    "        plt.subplots_adjust(top=0.95)\n",
    "        locs, labels = plt.xticks()\n",
    "        g.set_xticklabels(labels, rotation=90)\n",
    "        plt.gcf().suptitle(\"Number of unstable ({} datasets)\".format(len(dataset_df)))\n",
    "    plt.show()\n",
    "\n",
    "datasetsComposition(dataset_df, \"rate\")\n",
    "datasetsComposition(dataset_df, \"count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funded-validity",
   "metadata": {},
   "source": [
    "### 2.2. Loci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standing-suite",
   "metadata": {},
   "outputs": [],
   "source": [
    "loci_acc_df = getAccuracyDf(loci, results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forty-nepal",
   "metadata": {},
   "source": [
    "#### 2.2.a. Accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automotive-laugh",
   "metadata": {},
   "source": [
    "##### Find best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sonic-pocket",
   "metadata": {},
   "outputs": [],
   "source": [
    "by_config = {}\n",
    "for curr_dataset in sorted(set(loci_acc_df[\"dataset_id\"])):\n",
    "    acc_dataset_df = loci_acc_df[loci_acc_df[\"dataset_id\"] == curr_dataset]\n",
    "    acc_by_config = {}\n",
    "    for idx, row in acc_dataset_df.iterrows():\n",
    "        if row[\"config\"] not in by_config:\n",
    "            by_config[row[\"config\"]] = {\n",
    "                \"accuracy_sum\": 0,\n",
    "                \"classifier\": row[\"classifier\"],\n",
    "                \"padding\": row[\"padding\"],\n",
    "                \"min_support\": row[\"min_support\"],\n",
    "                \"duplicates\": row[\"duplicates\"],\n",
    "                \"stitching\": row[\"stitching\"],\n",
    "                \"config\": row[\"config\"],\n",
    "                \"rank_sum\": 0,\n",
    "                #\"rank_median\": 0\n",
    "            }\n",
    "        if row[\"config\"] not in acc_by_config:\n",
    "            acc_by_config[row[\"config\"]] = []\n",
    "        acc_by_config[row[\"config\"]].append(row[\"accuracy\"]) # List because several it exists one accuracy by marker in dataset for the config\n",
    "        by_config[row[\"config\"]][\"accuracy_sum\"] += row[\"accuracy\"]\n",
    "    # Manage rank by config\n",
    "    for cfg, accuracies in acc_by_config.items():\n",
    "        acc_by_config[cfg] = np.mean(accuracies)\n",
    "    sorted_acc = sorted(acc_by_config.items(), key=lambda elt: elt[1], reverse=True)\n",
    "    rank = 0\n",
    "    prev_acc = sorted_acc[0][1]\n",
    "    for cfg, acc in sorted_acc:\n",
    "        if prev_acc != acc:\n",
    "            rank += 1\n",
    "        by_config[cfg][\"rank_sum\"] += rank\n",
    "    \n",
    "acc_sum_df = pd.DataFrame(by_config.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constitutional-wells",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=\"accuracy_sum\", y=\"rank_sum\", data=acc_sum_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continental-assessment",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "display(acc_sum_df.sort_values(\"accuracy_sum\", ascending=False).head(100))\n",
    "pd.set_option('display.max_rows', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab98286-0ece-4b50-bb8f-7d9b21820a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.barplot(data=acc_sum_df, y=\"config\", x=\"accuracy_sum\")\n",
    "plt.gcf().set_size_inches(6, 8)  # Default [6, 4]\n",
    "plt.gcf().set_dpi(500)  # Default 72\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuing-reward",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "display(acc_sum_df.sort_values(\"rank_sum\", ascending=True).head(100))\n",
    "pd.set_option('display.max_rows', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c275677-5760-4c29-9123-7eb4d39732e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.barplot(data=acc_sum_df, y=\"config\", x=\"rank_sum\")\n",
    "plt.gcf().set_size_inches(6, 8)  # Default [6, 4]\n",
    "plt.gcf().set_dpi(500)  # Default 72\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "urban-space",
   "metadata": {},
   "source": [
    "##### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acceptable-manufacturer",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = loci_acc_df[\n",
    "    (loci_acc_df[\"duplicates\"] == retained[\"duplicates\"]) &\n",
    "    (loci_acc_df[\"min_support\"] == retained[\"min_support\"]) & \n",
    "    (loci_acc_df[\"padding\"] == retained[\"padding\"]) &\n",
    "    (loci_acc_df[\"stitching\"] == retained[\"stitching\"])\n",
    "]\n",
    "writePredStatus(filtered_df, 3, 0.85)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "julian-intention",
   "metadata": {},
   "source": [
    "#### 2.2.b. Prediction score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diverse-airplane",
   "metadata": {},
   "outputs": [],
   "source": [
    "writeScorePredStatus(\n",
    "    loci,\n",
    "    results_df[\n",
    "        (results_df[\"duplicates\"] == retained[\"duplicates\"]) &\n",
    "        (results_df[\"min_support\"] == retained[\"min_support\"]) & \n",
    "        (results_df[\"padding\"] == retained[\"padding\"]) &\n",
    "        (results_df[\"stitching\"] == retained[\"stitching\"])\n",
    "    ],\n",
    "    3,\n",
    "    0.92\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrative-apparatus",
   "metadata": {},
   "source": [
    "#### 2.2.c. Hard loci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepared-magic",
   "metadata": {},
   "outputs": [],
   "source": [
    "retained_agreement_df = results_df[\n",
    "    (results_df.classifier == retained[\"consensus\"][\"method\"]) &\n",
    "    (results_df[\"duplicates\"] == retained[\"duplicates\"]) &\n",
    "    (results_df[\"min_support\"] == retained[\"min_support\"]) & \n",
    "    (results_df[\"padding\"] == retained[\"padding\"]) &\n",
    "    (results_df[\"stitching\"] == retained[\"stitching\"])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dangerous-drink",
   "metadata": {},
   "outputs": [],
   "source": [
    "for locus in loci:\n",
    "    stat_by_lib = {lib: {\"library\": lib, \"datasets\": [], \"expected\": None,  \"right_pred\": 0, \"wrong_pred\": 0} for lib in set(retained_agreement_df[retained_agreement_df[locus + \"_pred_is_ok\"] != \"Undetermined\"][\"lib_name\"])}\n",
    "    for row_idx, row in retained_agreement_df.iterrows():\n",
    "        pred_status = row[locus + \"_pred_is_ok\"]\n",
    "        if pred_status != \"Undetermined\":\n",
    "            stat_by_lib[row[\"lib_name\"]][\"expected\"] = row[locus + \"_expected_status\"]\n",
    "            stat_by_lib[row[\"lib_name\"]][pred_status + \"_pred\"] += 1\n",
    "            stat_by_lib[row[\"lib_name\"]][\"datasets\"].append(row[\"dataset_id\"])\n",
    "    locus_hard_df = pd.DataFrame(stat_by_lib.values())\n",
    "    locus_hard_df[\"wrong_rate\"] = locus_hard_df.apply(lambda row: row[\"wrong_pred\"] / (row[\"right_pred\"] + row[\"wrong_pred\"]), axis=1)\n",
    "\n",
    "    print(locus)\n",
    "    pd.set_option('display.max_rows', None)\n",
    "    display(locus_hard_df[locus_hard_df[\"wrong_rate\"] >= 0.5])\n",
    "    pd.set_option('display.max_rows', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accomplished-grade",
   "metadata": {},
   "source": [
    "### 2.3. Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustained-maldives",
   "metadata": {},
   "outputs": [],
   "source": [
    "spl_acc_df = getAccuracyDf([\"spl\"], results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greatest-volleyball",
   "metadata": {},
   "source": [
    "#### 2.3.a. Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stone-steal",
   "metadata": {},
   "outputs": [],
   "source": [
    "by_config = {}\n",
    "for curr_dataset in sorted(set(spl_acc_df[\"dataset_id\"])):\n",
    "    acc_dataset_df = spl_acc_df[spl_acc_df[\"dataset_id\"] == curr_dataset]\n",
    "    acc_by_config = {}\n",
    "    for idx, row in acc_dataset_df.iterrows():\n",
    "        if row[\"config\"] not in by_config:\n",
    "            by_config[row[\"config\"]] = {\n",
    "                \"accuracy_sum\": 0,\n",
    "                \"classifier\": row[\"classifier\"],\n",
    "                \"padding\": row[\"padding\"],\n",
    "                \"min_support\": row[\"min_support\"],\n",
    "                \"duplicates\": row[\"duplicates\"],\n",
    "                \"stitching\": row[\"stitching\"],\n",
    "                \"config\": row[\"config\"],\n",
    "                \"rank_sum\": 0,\n",
    "                #\"rank_median\": 0\n",
    "            }\n",
    "        if row[\"config\"] not in acc_by_config:\n",
    "            acc_by_config[row[\"config\"]] = []\n",
    "        acc_by_config[row[\"config\"]].append(row[\"accuracy\"])\n",
    "        by_config[row[\"config\"]][\"accuracy_sum\"] += row[\"accuracy\"]\n",
    "    # Manage rank by config\n",
    "    for cfg, accuracies in acc_by_config.items():\n",
    "        acc_by_config[cfg] = np.mean(accuracies)\n",
    "    sorted_acc = sorted(acc_by_config.items(), key=lambda elt: elt[1], reverse=True)\n",
    "    rank = 0\n",
    "    prev_acc = sorted_acc[0][1]\n",
    "    for cfg, acc in sorted_acc:\n",
    "        if prev_acc != acc:\n",
    "            rank += 1\n",
    "        by_config[cfg][\"rank_sum\"] += rank\n",
    "    \n",
    "acc_sum_df = pd.DataFrame(by_config.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instrumental-drove",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=\"accuracy_sum\", y=\"rank_sum\", data=acc_sum_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corresponding-mandate",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "display(acc_sum_df.sort_values(\"accuracy_sum\", ascending=False).head(100))\n",
    "pd.set_option('display.max_rows', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "express-depth",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = spl_acc_df[\n",
    "    (spl_acc_df[\"duplicates\"] == retained[\"duplicates\"]) &\n",
    "    (spl_acc_df[\"min_support\"] == retained[\"min_support\"]) & \n",
    "    (spl_acc_df[\"padding\"] == retained[\"padding\"]) &\n",
    "    (spl_acc_df[\"stitching\"] == retained[\"stitching\"])\n",
    "]\n",
    "writePredStatus(filtered_df, 1, 0.85)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arabic-license",
   "metadata": {},
   "source": [
    "#### 2.3.b. Prediction score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hairy-fence",
   "metadata": {},
   "outputs": [],
   "source": [
    "writeScorePredStatus(\n",
    "    [\"spl\"],\n",
    "    results_df[\n",
    "        (results_df[\"duplicates\"] == retained[\"duplicates\"]) &\n",
    "        (results_df[\"min_support\"] == retained[\"min_support\"]) & \n",
    "        (results_df[\"padding\"] == retained[\"padding\"]) &\n",
    "        (results_df[\"stitching\"] == retained[\"stitching\"])\n",
    "    ],\n",
    "    3,\n",
    "    0.92\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleased-stream",
   "metadata": {},
   "source": [
    "#### 2.3.c. Hard samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "environmental-liverpool",
   "metadata": {},
   "outputs": [],
   "source": [
    "retained_agreement_df = results_df[\n",
    "    (results_df.classifier == retained[\"consensus\"][\"method\"]) &\n",
    "    (results_df[\"duplicates\"] == retained[\"duplicates\"]) &\n",
    "    (results_df[\"min_support\"] == retained[\"min_support\"]) & \n",
    "    (results_df[\"padding\"] == retained[\"padding\"]) &\n",
    "    (results_df[\"stitching\"] == retained[\"stitching\"])\n",
    "]\n",
    "wrong_spl_df = retained_agreement_df[retained_agreement_df[\"spl_pred_is_ok\"] == \"wrong\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olympic-vector",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "display(wrong_spl_df)\n",
    "pd.set_option('display.max_rows', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saved-drilling",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(retained_agreement_df[retained_agreement_df[\"lib_name\"].isin(wrong_spl_df[\"lib_name\"])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twelve-timeline",
   "metadata": {},
   "source": [
    "## 3. Results from balanced datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parliamentary-gazette",
   "metadata": {},
   "source": [
    "### 3.1. Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technical-district",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBalancedDf(locus, results_df, random_seed):\n",
    "    balanced_results_df = pd.DataFrame(columns=results_df.columns)\n",
    "    datasets_ids = set(results_df[\"dataset_id\"])\n",
    "    for curr_dataset in datasets_ids:\n",
    "        curr_dataset_df = results_df[results_df[\"dataset_id\"] == curr_dataset]\n",
    "        expected_stable = curr_dataset_df[\n",
    "            curr_dataset_df[\"{}_expected_status\".format(locus)] == \"MSS\"\n",
    "        ]\n",
    "        stable_ids = sorted(list(set(expected_stable[\"spl_name\"])))\n",
    "        expected_unstable = curr_dataset_df[\n",
    "            curr_dataset_df[\"{}_expected_status\".format(locus)] == \"MSI\"\n",
    "        ]\n",
    "        unstable_ids = sorted(list(set(expected_unstable[\"spl_name\"])))\n",
    "        sampling_size = min(len(stable_ids), len(unstable_ids))\n",
    "        random.seed(random_seed)\n",
    "        selected_spl = random.sample(stable_ids, sampling_size) + random.sample(unstable_ids, sampling_size)\n",
    "        balanced_results_df = balanced_results_df.append(\n",
    "            curr_dataset_df[curr_dataset_df[\"spl_name\"].isin(selected_spl)],\n",
    "            sort=False,\n",
    "            ignore_index=True\n",
    "        )\n",
    "    return balanced_results_df\n",
    "\n",
    "balanced_results_df = getBalancedDf(locus, results_df, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saved-business",
   "metadata": {},
   "outputs": [],
   "source": [
    "retained_agreement_df = balanced_results_df[\n",
    "    (balanced_results_df.classifier == retained[\"consensus\"][\"method\"]) &\n",
    "    (balanced_results_df[\"duplicates\"] == retained[\"duplicates\"]) &\n",
    "    (balanced_results_df[\"min_support\"] == retained[\"min_support\"]) & \n",
    "    (balanced_results_df[\"padding\"] == retained[\"padding\"]) &\n",
    "    (balanced_results_df[\"stitching\"] == retained[\"stitching\"])\n",
    "]\n",
    "desc_rows = []\n",
    "for dataset_id in set(retained_agreement_df[\"dataset_id\"]):\n",
    "    dataset_df = retained_agreement_df[retained_agreement_df[\"dataset_id\"] == dataset_id]\n",
    "    for idx, row in dataset_df.iterrows():\n",
    "        for locus in loci:\n",
    "            desc_rows.append({\n",
    "                \"dataset\": dataset_id,\n",
    "                \"locus\": locus,\n",
    "                \"status\": \"stable\",\n",
    "                \"count\": len(dataset_df[dataset_df[locus + \"_expected_status\"] == \"MSS\"])\n",
    "            })\n",
    "            desc_rows.append({\n",
    "                \"dataset\": dataset_id,\n",
    "                \"locus\": locus,\n",
    "                \"status\": \"unstable\",\n",
    "                \"count\": len(dataset_df[dataset_df[locus + \"_expected_status\"] == \"MSI\"])\n",
    "            })\n",
    "desc_df = pd.DataFrame(desc_rows)\n",
    "g = sns.boxplot(x=\"locus\", y=\"count\", hue=\"status\", data=desc_df, medianprops=dict(linewidth=2, color='firebrick'))\n",
    "locs, labels = plt.xticks()\n",
    "g.set_xticklabels(labels, rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "official-simple",
   "metadata": {},
   "source": [
    "### 3.2. Loci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arabic-classic",
   "metadata": {},
   "outputs": [],
   "source": [
    "loci_acc_balanced_df = getAccuracyDf(loci, balanced_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "paperback-jewel",
   "metadata": {},
   "source": [
    "#### 3.2.a. Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interim-context",
   "metadata": {},
   "outputs": [],
   "source": [
    "by_config = {}\n",
    "for curr_dataset in sorted(set(loci_acc_balanced_df[\"dataset_id\"])):\n",
    "    acc_dataset_df = loci_acc_balanced_df[loci_acc_balanced_df[\"dataset_id\"] == curr_dataset]\n",
    "    acc_by_config = {}\n",
    "    for idx, row in acc_dataset_df.iterrows():\n",
    "        if row[\"config\"] not in by_config:\n",
    "            by_config[row[\"config\"]] = {\n",
    "                \"accuracy_sum\": 0,\n",
    "                \"classifier\": row[\"classifier\"],\n",
    "                \"padding\": row[\"padding\"],\n",
    "                \"min_support\": row[\"min_support\"],\n",
    "                \"duplicates\": row[\"duplicates\"],\n",
    "                \"stitching\": row[\"stitching\"],\n",
    "                \"config\": row[\"config\"],\n",
    "                \"rank_sum\": 0,\n",
    "                \"rank_median\": 0\n",
    "            }\n",
    "        if row[\"config\"] not in acc_by_config:\n",
    "            acc_by_config[row[\"config\"]] = []\n",
    "        acc_by_config[row[\"config\"]].append(row[\"accuracy\"]) # List because several it exists one accuracy by marker in dataset for the config\n",
    "        by_config[row[\"config\"]][\"accuracy_sum\"] += row[\"accuracy\"]\n",
    "    # Manage rank by config\n",
    "    for cfg, accuracies in acc_by_config.items():\n",
    "        acc_by_config[cfg] = np.mean(accuracies)\n",
    "    sorted_acc = sorted(acc_by_config.items(), key=lambda elt: elt[1], reverse=True)\n",
    "    rank = 0\n",
    "    prev_acc = sorted_acc[0][1]\n",
    "    for cfg, acc in sorted_acc:\n",
    "        if prev_acc != acc:\n",
    "            rank += 1\n",
    "        by_config[cfg][\"rank_sum\"] += rank\n",
    "    \n",
    "acc_sum_df = pd.DataFrame(by_config.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radical-contact",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=\"accuracy_sum\", y=\"rank_sum\", data=acc_sum_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaningful-hardware",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_rows', None)\n",
    "#display(acc_sum_df.sort_values(\"accuracy_sum\", ascending=False).head(100))\n",
    "#pd.set_option('display.max_rows', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd34e87-ebd2-4eb3-8759-4b9c1b8e0802",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.barplot(data=acc_sum_df, y=\"config\", x=\"accuracy_sum\")\n",
    "plt.gcf().set_size_inches(6, 8)  # Default [6, 4]\n",
    "plt.gcf().set_dpi(500)  # Default 72\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statutory-discount",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_rows', None)\n",
    "#display(acc_sum_df.sort_values(\"rank_sum\", ascending=True).head(100))\n",
    "#pd.set_option('display.max_rows', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d1e0d0-0dd8-4672-a53e-5123d6e31ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.barplot(data=acc_sum_df, y=\"config\", x=\"rank_sum\")\n",
    "plt.gcf().set_size_inches(6, 8)  # Default [6, 4]\n",
    "plt.gcf().set_dpi(500)  # Default 72\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stopped-absorption",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = loci_acc_balanced_df[\n",
    "    (loci_acc_balanced_df[\"duplicates\"] == retained[\"duplicates\"]) &\n",
    "    (loci_acc_balanced_df[\"min_support\"] == retained[\"min_support\"]) & \n",
    "    (loci_acc_balanced_df[\"padding\"] == retained[\"padding\"]) &\n",
    "    (loci_acc_balanced_df[\"stitching\"] == retained[\"stitching\"])\n",
    "]\n",
    "writePredStatus(filtered_df, 3, 0.85)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "widespread-parliament",
   "metadata": {},
   "source": [
    "#### 3.2.b. Prediction score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beautiful-greek",
   "metadata": {},
   "outputs": [],
   "source": [
    "writeScorePredStatus(\n",
    "    loci,\n",
    "    balanced_results_df[\n",
    "        (balanced_results_df[\"duplicates\"] == retained[\"duplicates\"]) &\n",
    "        (balanced_results_df[\"min_support\"] == retained[\"min_support\"]) & \n",
    "        (balanced_results_df[\"padding\"] == retained[\"padding\"]) &\n",
    "        (balanced_results_df[\"stitching\"] == retained[\"stitching\"])\n",
    "    ],\n",
    "    3,\n",
    "    0.92\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f848d0c-93cb-435c-a2a1-bd9239b888c6",
   "metadata": {},
   "source": [
    "## 4. Release summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5626661b-98be-486a-997b-18ef2c88db3f",
   "metadata": {},
   "source": [
    "### 4.1. Loci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c00f0f-09ee-4a02-99fb-03f7401bdd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "loci_acc_df = getAccuracyDf(loci, results_df)\n",
    "filtered_df = loci_acc_df[\n",
    "    (loci_acc_df[\"classifier\"].isin(retained[\"classifiers\"])) &\n",
    "    (loci_acc_df[\"duplicates\"] == retained[\"duplicates\"]) &\n",
    "    (loci_acc_df[\"min_support\"] == retained[\"min_support\"]) & \n",
    "    (loci_acc_df[\"padding\"] == retained[\"padding\"]) &\n",
    "    (loci_acc_df[\"stitching\"] == retained[\"stitching\"])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a2b647-eed6-4782-aaa9-9025bcdf30f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loci_acc_cmp_df = filtered_df.groupby([\"config\"]).apply(\n",
    "    lambda x: pd.Series(\n",
    "        [\n",
    "            sum(x[\"nb_right_prediction\"]),\n",
    "            sum(x[\"nb_wrong_prediction\"]),\n",
    "            sum(x[\"nb_without_prediction\"]),\n",
    "        ],\n",
    "        index=[\n",
    "            'nb_true', 'nb_false', 'nb_undetermined'\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "loci_acc_cmp_df = loci_acc_cmp_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919d0dd5-b785-49ef-9fdc-049ed057d1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "loci_acc_cmp_df.sort_values(\"nb_false\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbac0824-c76e-4aed-8b60-c894e1f07de1",
   "metadata": {},
   "source": [
    "### 4.2. Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe10f2e-08df-4efa-a8f5-127cb73a0fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "spl_acc_df = getAccuracyDf([\"spl\"], results_df)\n",
    "filtered_df = spl_acc_df[\n",
    "    (spl_acc_df[\"classifier\"].isin(retained[\"classifiers\"])) &\n",
    "    (spl_acc_df[\"duplicates\"] == retained[\"duplicates\"]) &\n",
    "    (spl_acc_df[\"min_support\"] == retained[\"min_support\"]) & \n",
    "    (spl_acc_df[\"padding\"] == retained[\"padding\"]) &\n",
    "    (spl_acc_df[\"stitching\"] == retained[\"stitching\"])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119f6b36-d1fb-4fd5-ab76-4b46afe38565",
   "metadata": {},
   "outputs": [],
   "source": [
    "spl_acc_cmp_df = filtered_df.groupby([\"config\"]).apply(\n",
    "    lambda x: pd.Series(\n",
    "        [\n",
    "            sum(x[\"nb_right_prediction\"]),\n",
    "            sum(x[\"nb_wrong_prediction\"]),\n",
    "            sum(x[\"nb_without_prediction\"]),\n",
    "        ],\n",
    "        index=[\n",
    "            'nb_true', 'nb_false', 'nb_undetermined'\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "spl_acc_cmp_df = spl_acc_cmp_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576129fb-ab25-4d2a-99b6-48e6f40590e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "spl_acc_cmp_df.sort_values(\"nb_false\", ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
